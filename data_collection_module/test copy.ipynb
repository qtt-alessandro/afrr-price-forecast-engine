{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "283404a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from arch import arch_model\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly_resampler import FigureResampler, FigureWidgetResampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30cedf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_imbalance_price(start_date, end_date, price_area=\"DK1\", sort_by=\"TimeUTC ASC\", imbalance_type=\"afrr\"):\n",
    "    \n",
    "    COLS_SEL = ['TimeUTC', 'BalancingDemand','SpotPriceEUR','DominatingDirection']\n",
    "    \n",
    "    if isinstance(start_date, pd.Timestamp):\n",
    "        start_date = start_date.strftime(\"%Y-%m-%dT%H:%M\")\n",
    "    if isinstance(end_date, pd.Timestamp):\n",
    "        end_date = end_date.strftime(\"%Y-%m-%dT%H:%M\")\n",
    "    \n",
    "    base_url = \"https://api.energidataservice.dk/dataset/ImbalancePrice\"\n",
    "    \n",
    "    url = f\"{base_url}?offset=0&start={start_date}&end={end_date}&filter={{\\\"PriceArea\\\":[\\\"{price_area}\\\"]}}&sort={sort_by}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data.get(\"records\", []))\n",
    "        \n",
    "        if imbalance_type == \"afrr\":\n",
    "            COLS_SEL.extend(['aFRRUpMW', 'aFRRVWAUpEUR', 'aFRRDownMW', 'aFRRVWADownEUR'])\n",
    "            return df[COLS_SEL].set_index('TimeUTC')\n",
    "        elif imbalance_type == \"mfrr\":\n",
    "            COLS_SEL.append(['mFRRVWAUpEUR', 'mFRRVWADownEUR'])\n",
    "            return df[[COLS_SEL]].set_index('TimeUTC')\n",
    "            \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "    \n",
    "    \n",
    "start = pd.Timestamp('20240101', tz='Europe/Copenhagen')\n",
    "end = pd.Timestamp('20250501', tz='Europe/Copenhagen')\n",
    "df = get_imbalance_price(start_date=start, end_date=end, price_area=\"DK1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88487cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from arch import arch_model\n",
    "\n",
    "# Your existing code\n",
    "df['res_aFRRVWAUp'] = df['SpotPriceEUR'] - df['aFRRVWAUpEUR'].rolling(24).mean()\n",
    "df['res_aFRRVWADown'] = df['SpotPriceEUR'] - df['aFRRVWADownEUR'].rolling(24).mean()\n",
    "\n",
    "df = df.dropna(subset=['res_aFRRVWAUp', 'res_aFRRVWADown'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_garch_model(residuals, p=1, q=1, lags=1, disp = \"off\"):\n",
    "    model = arch_model(residuals, mean='AR', lags=lags, vol='GARCH', p=p, q=q)\n",
    "    result = model.fit(disp=disp)\n",
    "    return result, result.resid\n",
    "\n",
    "def forecast_garch_variance(arch_model, custom_residual=None, horizon=1):\n",
    "\n",
    "    omega = arch_model.params['omega']\n",
    "    alpha = arch_model.params['alpha[1]']\n",
    "    beta = arch_model.params['beta[1]']\n",
    "    \n",
    "    if custom_residual is not None:\n",
    "        last_resid = custom_residual\n",
    "    else:\n",
    "        last_resid = arch_model.resid[-1]\n",
    "    \n",
    "    last_var = arch_model.conditional_volatility[-1]**2\n",
    "    variance_forecast = np.zeros(horizon)\n",
    "    for h in range(horizon):\n",
    "        if h == 0:\n",
    "            variance_forecast[h] = omega + alpha * last_resid**2 + beta * last_var\n",
    "        else:\n",
    "            variance_forecast[h] = omega + (alpha + beta) * variance_forecast[h-1]\n",
    "    \n",
    "    volatility_forecast = np.sqrt(variance_forecast)\n",
    "    \n",
    "    return volatility_forecast\n",
    "\n",
    "\n",
    "\n",
    "def generate_copula_forecasts(df, residual_cols, quantiles=[0.1, 0.5, 0.9]):\n",
    "    \n",
    "    result_df = df.copy()\n",
    "    residuals_data = df[residual_cols].dropna()\n",
    "    \n",
    "    copula = GaussianMultivariate()\n",
    "    copula.fit(residuals_data)\n",
    "    \n",
    "    # Number of simulations per row\n",
    "    n_sims = 1000\n",
    "    \n",
    "    # For each row in the dataset\n",
    "    for i, _ in df.iterrows():\n",
    "        # Generate samples for this row\n",
    "        samples = copula.sample(n_sims)\n",
    "        \n",
    "        # Calculate quantiles for each residual column\n",
    "        for col in residual_cols:\n",
    "            for q in quantiles:\n",
    "                q_str = f\"{int(q*100)}\"\n",
    "                new_col_name = f\"{col}_q{q_str}\"\n",
    "                \n",
    "                # Calculate the quantile from the samples\n",
    "                q_value = samples[col].quantile(q)\n",
    "                \n",
    "                # Assign the quantile value to this specific row\n",
    "                result_df.loc[i, new_col_name] = q_value\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def forecast_garch_column(df, column_name, arch_model):\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    for idx in result_df.index:\n",
    "        custom_residual = result_df.loc[idx, column_name]\n",
    "        \n",
    "        volatility_forecast = forecast_garch_variance(\n",
    "            arch_model,\n",
    "            custom_residual=custom_residual,\n",
    "            horizon=1\n",
    "        )\n",
    "        \n",
    "        result_df.loc[idx, f\"{column_name}_vol\"] = volatility_forecast[0]\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d0027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_garch_res_aFRRVWAUp, df['res_aFRRVWAUp_cop'] = fit_garch_model(df['res_aFRRVWAUp'], p=1, q=1, lags=1)\n",
    "model_garch_res_aFRRVWADown, df['res_aFRRVWADown_cop'] = fit_garch_model(df['res_aFRRVWADown'], p=1, q=1, lags=1)\n",
    "\n",
    "xdf = df[['res_aFRRVWAUp', 'res_aFRRVWAUp_cop_q10', 'res_aFRRVWAUp_cop_q90']]\n",
    "forecasted_df = forecast_garch_column(xdf, 'res_aFRRVWAUp_cop_q10', model_garch_res_aFRRVWAUp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3089da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44606a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c277b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e587f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
